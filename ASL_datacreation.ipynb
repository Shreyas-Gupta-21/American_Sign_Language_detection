{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK FOR DATASET CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS NOTEBOOK IS FOR DATASET CREATION , ANYONE CAN MAKE THEIR OWN DATASET USING THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING NECESSARY LIBRARIES\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to accumulate weight of background , so that we can detect if any object coming into the frame ,This method basically used for object detection \n",
    "I am providing is an small article from where you can get intuition\n",
    "LINK: https://opencvpython.blogspot.com/2012/07/background-extraction-using-running.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "background=None\n",
    "alpha=0.5\n",
    "def accumulated_weight(frame,alpha):\n",
    "    global background\n",
    "    if(background is None):\n",
    "        background=frame.copy().astype(\"float\")\n",
    "    cv2.accumulateWeighted(frame,background,alpha)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand Segmentation is used to detect hand by calculating difference between foreground and background when hand comes into the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_segmentation(frame,threshold=25):\n",
    "    global background\n",
    "    diff=cv2.absdiff(background.astype('uint8'),frame)\n",
    "    \n",
    "    _,thresholded=cv2.threshold(diff,threshold,255,cv2.THRESH_BINARY) \n",
    "    \n",
    "    '''Used for thresholding the image(i.e If a pixel value is greater than threshold provided, pixel value 255 is given and \n",
    "    0 if pixel value is smaller than threshohld)'''\n",
    "    \n",
    "    contours,hei=cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    '''findContours is used to find boundaries in a image for example finding  boundary of a rectangle in a image in this case \n",
    "    it will find boundaries of our hand and it prefers to work with thresholded images'''\n",
    "    \n",
    "    if(len(contours)==0):\n",
    "        return(None)\n",
    "    \n",
    "    else:\n",
    "        hand_segment_max=max(contours,key=cv2.contourArea)\n",
    "        return(thresholded,hand_segment_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n",
      "ADJUST ANOTHER SIGN IN FIVE SECONDS\n"
     ]
    }
   ],
   "source": [
    "dic={1:\"A\",2:\"B\",3:\"C\",4:\"D\",5:\"E\",6:\"F\",7:\"G\",8:\"H\",9:\"I\",10:\"J\",11:\"K\",12:\"L\",13:\"M\",14:\"N\",\n",
    "          15:\"O\",16:\"P\",17:\"Q\",18:\"R\",19:\"S\",20:\"T\",21:\"U\",22:\"V\",23:\"W\",24:\"X\",25:\"Y\",26:\"Z\"}\n",
    "\n",
    "\n",
    "for i in range(1,len(dic)+1): #Running loop for all 26 alphabets\n",
    "    time.sleep(5) #Pausing the loop for 5 seconds to adjust for  next ASL signs\n",
    "    print(\"ADJUST ANOTHER SIGN IN FIVE SECONDS\")\n",
    "    \n",
    "    cam=cv2.VideoCapture(0) #Opening the camera\n",
    "    num_frames=0\n",
    "    element=i\n",
    "    num_images_taken=0\n",
    "    \n",
    "    #Frame where we adjust our hand and create dataset\n",
    "    ROI_top = 100\n",
    "    ROI_bottom = 300\n",
    "    ROI_right = 150\n",
    "    ROI_left = 350\n",
    "\n",
    "    while(True):\n",
    "        ret,frame=cam.read() #reading real time camera pictures\n",
    "    \n",
    "        frame=cv2.flip(frame,1) #flipping the camera \n",
    "    \n",
    "        frame_copy=frame.copy() #making copy of a frame (Real time display i.e the bigger one)\n",
    "    \n",
    "        roi=frame[ROI_top:ROI_bottom,ROI_right:ROI_left] #Region of Interest\n",
    "    \n",
    "        gray_frame=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY) #Converting Frame to RGB to gray\n",
    "    \n",
    "        gray_frame=cv2.GaussianBlur(gray_frame,(9,9),0) #Gaussian Blurring(Refer GFG)\n",
    "    \n",
    "        if(num_frames<60): '''This loop is for fetching the background \n",
    "        so that it can calculate difference between foreground and background (60 frames will be enough)'''\n",
    "            \n",
    "            accumulated_weight(gray_frame,alpha)\n",
    "            if(num_frames<=59):\n",
    "            \n",
    "                cv2.putText(frame_copy,\"FETCHING BACKGROUND...PLEASE WAIT\",(80,400),cv2.FONT_HERSHEY_SIMPLEX,0.9,(0,0,255),2)\n",
    "            \n",
    "        elif(num_frames<=300): \n",
    "            '''Adjusting hand gestures so that dataset will be good created(It is important) '''\n",
    "            hand=hand_segmentation(gray_frame)\n",
    "        \n",
    "            cv2.putText(frame_copy,\"ADJUST HAND FOR\"+ dic[element],(200,400),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "        \n",
    "            if(hand is not None): #If hand is detected in the frame \n",
    "                thresholded,hand_segment=hand\n",
    "            \n",
    "                cv2.drawContours(frame_copy,[hand_segment+(ROI_right,ROI_top)],-1,(255,0,0),2) #Drawing Contours(Blue Color)\n",
    "            \n",
    "                cv2.putText(frame_copy, str(num_frames)+\"For\" + dic[element],(70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "                cv2.imshow(\"THRESHOLDED IMAGE\",thresholded) #Displaying the thresholded Image\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            '''This loop is for saving image into local memory (Upto 300 images for each alphabet)'''\n",
    "            hand=hand_segmentation(gray_frame)\n",
    "        \n",
    "            if(hand is not None):\n",
    "                thresholded,hand_segment=hand\n",
    "            \n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right,ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "                cv2.putText(frame_copy, str(num_frames)+\"For\" + dic[element],(70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "                cv2.putText(frame_copy, str(num_images_taken) + 'images' +\"For\"+ dic[element],(200, 400), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255), 2)\n",
    "            \n",
    "                cv2.imshow(\"THRESHOLDED IMAGE\",thresholded)\n",
    "            \n",
    "                if num_images_taken <= 300:\n",
    "                    directory=r\"C:/Users/Aryan Chauhan/Desktop/AIO/GESTURE/TRAIN\" #Directory where we want to save our data\n",
    "                    os.chdir(directory) #changing the directory\n",
    "                    directory_for_elements=dic[element]  \n",
    "                    path=os.path.join(directory,directory_for_elements) #Making directory for each alphabet\n",
    "                    try:\n",
    "                        os.mkdir(directory_for_elements) #Making of new directory\n",
    "                    except OSError as error:\n",
    "                        pass\n",
    "                    os.chdir(directory_for_elements) \n",
    "                    filename=dic[element]+str(num_images_taken+300)+\".jpg\"\n",
    "                    h=cv2.imwrite(filename, thresholded)  #Saving the images\n",
    "                    \n",
    "                \n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "                num_images_taken+=1\n",
    "            \n",
    "            else:\n",
    "                cv2.putText(frame_copy,\"NO HAND DETECTED\",(200,400),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "            \n",
    "            \n",
    "        cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,ROI_bottom), (255,128,0), 3)\n",
    "    \n",
    "        cv2.putText(frame_copy, \"Hand sign recognition_ _ _\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    \n",
    "        num_frames+=1\n",
    "    \n",
    "        cv2.imshow(\"SIGN DETECTION\",frame_copy)\n",
    "    \n",
    "        if(cv2.waitKey(25) & 0xFF==ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
